# AI Router

> **Route to intelligence, don't build it.**

```
Template: ai-router
Org: BlackRoad-AI (AI)
Status: READY
Version: 0.1.0
```

---

## What It Does

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           AI ROUTER                 â”‚
                    â”‚   Route to intelligence             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼             â–¼           â–¼           â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ OpenAI  â”‚   â”‚Anthropicâ”‚ â”‚ Hailo-8 â”‚ â”‚ Ollama  â”‚ â”‚  More   â”‚
    â”‚  GPT-4  â”‚   â”‚ Claude  â”‚ â”‚  Local  â”‚ â”‚  Local  â”‚ â”‚   ...   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The AI Router provides:

1. **Unified API** - One interface for all providers
2. **Smart Routing** - Strategy-based provider selection
3. **Automatic Fallback** - If one fails, try the next
4. **Cost Tracking** - Know exactly what you're spending
5. **Signal Emission** - BlackRoad mesh integration

---

## Quick Start

```bash
# Install
pip install -r requirements.txt

# Set API keys
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."

# Run
python -m ai_router complete "What is 2+2?"

# With specific provider
python -m ai_router complete "Write code" --provider anthropic

# With fallback chain (try local first)
python -m ai_router complete "Analyze" --chain hailo,ollama,openai

# Interactive mode
python -m ai_router interactive
```

---

## Providers

| Provider | Type | Models | Cost |
|----------|------|--------|------|
| **OpenAI** | Cloud | GPT-4o, GPT-4o-mini, GPT-3.5 | $$ |
| **Anthropic** | Cloud | Claude Opus 4, Sonnet 4, Haiku | $$ |
| **Hailo** | Local | Quantized LLMs (Pi + Hailo-8) | FREE |
| **Ollama** | Local | Llama, Mistral, Phi, CodeLlama | FREE |

---

## Routing Strategies

```python
from ai_router import Router

# Cost optimized (default) - cheapest first
router = Router(strategy="cost")

# Latency optimized - fastest first
router = Router(strategy="latency")

# Quality optimized - best model first
router = Router(strategy="quality")

# Local first - always try local before cloud
router = Router(strategy="local_first")

# Cloud first - always try cloud for quality
router = Router(strategy="cloud_first")
```

### Strategy Priority

| Strategy | Priority Order |
|----------|----------------|
| cost | Hailo â†’ Ollama â†’ GPT-4o-mini â†’ Claude Haiku |
| latency | Hailo â†’ Ollama â†’ GPT-4o-mini â†’ Claude Haiku |
| quality | Claude Opus â†’ GPT-4o â†’ Claude Sonnet â†’ Local |
| local_first | Hailo â†’ Ollama â†’ Any Cloud |
| cloud_first | Anthropic â†’ OpenAI â†’ Local |

---

## Python API

```python
from ai_router import Router

router = Router()

# Simple completion
result = await router.complete("What is the meaning of life?")
print(result.content)
print(f"Cost: ${result.total_cost:.4f}")

# With specific provider
result = await router.complete(
    "Write a Python function",
    provider="anthropic",
    model="claude-sonnet-4-20250514"
)

# With fallback chain
result = await router.complete(
    "Analyze this image",
    chain=["hailo", "ollama", "openai"]
)

# Stream response
async for chunk in router.complete_stream("Tell me a story"):
    print(chunk, end="", flush=True)

# Generate embeddings
embeddings = await router.embed("Hello world")
print(f"Dimensions: {embeddings.dimensions}")

# Check health
health = await router.health_check_all()
for provider, status in health.items():
    print(f"{provider}: {status.value}")
```

---

## Cost Tracking

```python
from ai_router import Router
from ai_router.tracking import CostTracker

tracker = CostTracker(storage_path=".costs.json")
router = Router()

# Track usage
result = await router.complete("Hello")
tracker.record_response(result.response)

# Get report
report = tracker.report(period="day")
print(report.summary())
# Cost Report: 2026-01-27 to 2026-01-28
# Total Cost:     $0.0234
# Total Tokens:   15,432
# Total Requests: 47
# By Provider:
#   anthropic: $0.0180 (23 requests)
#   openai: $0.0054 (24 requests)

# Set budget alerts
if tracker.total_cost > 10.0:
    print("Budget exceeded!")
```

---

## CLI Commands

```bash
# Complete a prompt
ai-router complete "What is 2+2?"
ai-router complete "Write code" --provider anthropic
ai-router complete "Analyze" --chain hailo,ollama,openai
ai-router complete "Hello" --strategy quality

# Stream response
ai-router stream "Tell me a story"

# Generate embeddings
ai-router embed "Hello world"
ai-router embed "Hello" --show-vector

# Check provider health
ai-router health

# Show cost report
ai-router costs --period day
ai-router costs --period week

# Interactive mode
ai-router interactive
```

---

## Directory Structure

```
ai-router/
â”œâ”€â”€ ai_router/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py          â† Provider interface
â”‚   â”‚   â”œâ”€â”€ openai.py        â† GPT-4, embeddings
â”‚   â”‚   â”œâ”€â”€ anthropic.py     â† Claude
â”‚   â”‚   â”œâ”€â”€ hailo.py         â† On-device (Hailo-8)
â”‚   â”‚   â””â”€â”€ ollama.py        â† Local LLMs
â”‚   â”œâ”€â”€ routing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router.py        â† Main router
â”‚   â”‚   â””â”€â”€ strategy.py      â† Routing strategies
â”‚   â”œâ”€â”€ tracking/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ costs.py         â† Cost tracking
â”‚   â””â”€â”€ signals/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ emitter.py       â† Signal emission
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Configuration

```yaml
# config.yaml
providers:
  openai:
    enabled: true
    default_model: gpt-4o-mini
    api_key: ${OPENAI_API_KEY}

  anthropic:
    enabled: true
    default_model: claude-3-5-haiku-20241022
    api_key: ${ANTHROPIC_API_KEY}

  hailo:
    enabled: true
    default_model: tinyllama-1b-q4
    base_url: http://lucidia:5000

  ollama:
    enabled: true
    default_model: llama3.2
    base_url: http://localhost:11434

routing:
  default_strategy: cost
  fallback_enabled: true
  max_retries: 3

tracking:
  enabled: true
  storage_path: .ai-router-costs.json

signals:
  enabled: true
  target: OS
```

---

## Signals

```
ğŸ§  AI â†’ OS : inference_start, provider=anthropic, model=claude-3.5-sonnet
âœ… AI â†’ OS : inference_complete, provider=anthropic, latency_ms=450, cost=$0.0032
âŒ AI â†’ OS : inference_failed, provider=hailo, error=device_busy
ğŸ”„ AI â†’ OS : fallback_triggered, from=hailo, to=ollama
ğŸŸ¢ AI â†’ OS : provider_healthy, provider=openai
ğŸ”´ AI â†’ OS : provider_down, provider=hailo
ğŸ’° AI â†’ OS : cost_alert, total=$10.50, period=day, threshold=$10.00
```

---

## Integration with BlackRoad

```python
# In the Operator
from ai_router import Router

router = Router(strategy="local_first")

async def handle_ai_query(query: str):
    # Route to the best AI provider
    result = await router.complete(query)

    # Emit signal
    print(result.signal())
    # ğŸ§  AI â†’ OS : inference_complete, provider=hailo@lucidia, latency=85ms, cost=$0.00

    return result.content
```

---

## Adding a New Provider

```python
from ai_router.providers.base import Provider, ProviderConfig, CompletionResponse

class MyProvider(Provider):
    async def complete(self, request):
        # Your implementation
        return CompletionResponse(
            content="Hello!",
            model="my-model",
            provider=self.name,
            cost=0.001,
            latency_ms=100,
        )

    async def health_check(self):
        # Check if available
        return ProviderStatus.HEALTHY

# Register
router = Router(providers=[MyProvider(config)])
```

---

*Route to intelligence. Own the routing.*
